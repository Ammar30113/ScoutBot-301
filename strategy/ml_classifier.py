from __future__ import annotations

from pathlib import Path
from typing import Dict, Iterable, List, Tuple

import joblib
import numpy as np
import pandas as pd
from xgboost import XGBClassifier

from core.logger import get_logger
from data.price_router import PriceRouter
from strategy.sentiment_engine import sentiment_score

logger = get_logger(__name__)

MODEL_PATH = Path("models/momentum_sentiment_model.pkl")
FEATURE_COLUMNS = [
    "rsi",
    "macd_hist",
    "return_5d",
    "return_20d",
    "volume_delta",
    "volatility_20d",
    "sentiment_score",
]

price_router = PriceRouter()


class MLClassifier:
    def __init__(self, model_path: Path = MODEL_PATH) -> None:
        self.model_path = model_path
        self.model = self._load_or_train_model()

    def _load_or_train_model(self) -> XGBClassifier:
        self.model_path.parent.mkdir(parents=True, exist_ok=True)
        if self.model_path.exists():
            try:
                return joblib.load(self.model_path)
            except Exception as exc:  # pragma: no cover - defensive log
                logger.warning("Existing ML model %s is unreadable (%s); retraining", self.model_path, exc)
        model = self._train_model()
        joblib.dump(model, self.model_path)
        return model

    def _train_model(self) -> XGBClassifier:
        symbols = ["SPY", "QQQ", "IWM", "AAPL", "MSFT", "NVDA", "AMD", "AMZN", "META", "GOOG"]
        X_rows: List[List[float]] = []
        y_rows: List[int] = []

        for symbol in symbols:
            try:
                bars = price_router.get_aggregates(symbol, "1day", 260)
                df = PriceRouter.aggregates_to_dataframe(bars)
            except Exception as exc:  # pragma: no cover - network guard
                logger.warning("Training data unavailable for %s: %s", symbol, exc)
                continue
            if df.empty or len(df) < 40:
                continue

            sent = sentiment_score(symbol)
            closes = df["close"].astype(float)
            for idx in range(20, min(len(df) - 1, 220)):
                window = df.iloc[max(0, idx - 60) : idx + 1]
                feats = build_features(window, sent)
                next_close = float(closes.iloc[idx + 1])
                curr_close = float(closes.iloc[idx])
                label = 1 if next_close >= curr_close * 1.01 else 0
                X_rows.append([feats[col] for col in FEATURE_COLUMNS])
                y_rows.append(label)
                if len(X_rows) >= 400:
                    break
            if len(X_rows) >= 400:
                break

        if len(X_rows) < 50:
            rng = np.random.default_rng(42)
            samples = 300
            X_rows = rng.normal(size=(samples, len(FEATURE_COLUMNS))).tolist()
            weights = np.array([0.2, 0.2, 0.2, 0.2, 0.1, 0.05, 0.15])
            logits = (np.array(X_rows) @ weights) + rng.normal(scale=0.3, size=samples)
            y_rows = (logits > 0).astype(int).tolist()

        model = XGBClassifier(
            n_estimators=200,
            max_depth=5,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            eval_metric="logloss",
        )
        model.fit(np.array(X_rows), np.array(y_rows))
        return model

    def predict(self, features: Dict[str, float]) -> float:
        vector = np.array([[features.get(col, 0.0) for col in FEATURE_COLUMNS]])
        proba = self.model.predict_proba(vector)[0][1]
        return float(np.clip(proba, 0.0, 1.0))


def build_features(price_frame: pd.DataFrame, sent_score: float) -> Dict[str, float]:
    if price_frame.empty or len(price_frame) < 20:
        return {col: 0.0 for col in FEATURE_COLUMNS}

    close = price_frame["close"].astype(float)
    high = price_frame["high"].astype(float)
    low = price_frame["low"].astype(float)
    volume = price_frame["volume"].astype(float).replace(0, np.nan)

    rsi_val = _rsi(close)
    macd_val = _macd_hist(close)
    ret_5 = close.iloc[-1] / close.iloc[-6] - 1 if len(close) > 5 and close.iloc[-6] else 0.0
    ret_20 = close.iloc[-1] / close.iloc[-21] - 1 if len(close) > 20 and close.iloc[-21] else 0.0
    vol_delta = volume.iloc[-1] / volume.rolling(window=20, min_periods=1).mean().iloc[-1] if len(volume) else 0.0
    volatility = float(close.pct_change().rolling(window=20, min_periods=1).std().iloc[-1])

    return {
        "rsi": rsi_val,
        "macd_hist": macd_val,
        "return_5d": ret_5,
        "return_20d": ret_20,
        "volume_delta": vol_delta,
        "volatility_20d": volatility,
        "sentiment_score": sent_score,
    }


def _rsi(close: pd.Series, window: int = 14) -> float:
    delta = close.diff()
    gain = delta.clip(lower=0).rolling(window=window, min_periods=window).mean()
    loss = -delta.clip(upper=0).rolling(window=window, min_periods=window).mean()
    if loss is None or loss.iloc[-1] == 0:
        return 100.0
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return float(rsi.iloc[-1]) if not rsi.empty else 0.0


def _macd_hist(close: pd.Series) -> float:
    ema_fast = close.ewm(span=12, adjust=False).mean()
    ema_slow = close.ewm(span=26, adjust=False).mean()
    macd_val = ema_fast - ema_slow
    signal = macd_val.ewm(span=9, adjust=False).mean()
    hist = macd_val - signal
    return float(hist.iloc[-1]) if not hist.empty else 0.0


_ml_classifier = MLClassifier()


def generate_predictions(universe: Iterable[str]) -> List[Tuple[str, float, Dict[str, float]]]:
    predictions: List[Tuple[str, float, Dict[str, float]]] = []
    for symbol in universe:
        try:
            bars = price_router.get_aggregates(symbol, "1day", 120)
        except Exception as exc:  # pragma: no cover - network guard
            logger.warning("Aggregates unavailable for %s: %s", symbol, exc)
            continue
        price_frame = PriceRouter.aggregates_to_dataframe(bars)
        if price_frame.empty:
            logger.warning("No price data for %s", symbol)
            continue

        sent_score = sentiment_score(symbol)
        features = build_features(price_frame, sent_score)
        prob = _ml_classifier.predict(features)
        predictions.append((symbol, prob, features))
        logger.info("ML probability for %s â†’ %.3f", symbol, prob)
    return predictions
